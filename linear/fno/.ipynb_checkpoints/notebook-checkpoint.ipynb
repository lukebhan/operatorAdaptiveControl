{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b10c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Adam import Adam\n",
    "from timeit import default_timer\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from fourier import FNO1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade990aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = np.loadtxt(\"x.dat\", dtype=np.float32)\n",
    "y = np.loadtxt(\"y.dat\", dtype=np.float32)\n",
    "x = x.reshape(x.shape[0], x.shape[1] // 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a21292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nt = 100\n",
    "epochs = 500\n",
    "ntrain = 900\n",
    "ntest = 100\n",
    "batch_size = 20\n",
    "gamma = 0.5\n",
    "learning_rate = 0.0001\n",
    "step_size= 50\n",
    "modes=12\n",
    "width=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb540987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=1)\n",
    "x_train = torch.from_numpy(x_train).cuda()\n",
    "y_train = torch.from_numpy(y_train).cuda()\n",
    "x_test = torch.from_numpy(x_test).cuda()\n",
    "y_test = torch.from_numpy(y_test).cuda()\n",
    "trainData = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "testData = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfea9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    c = 0\n",
    "    for p in list(model.parameters()):\n",
    "        c += reduce(operator.mul, \n",
    "                    list(p.size()+(2,) if p.is_complex() else p.size()))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef6d9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107009\n"
     ]
    }
   ],
   "source": [
    "model = FNO1d(modes, width).cuda()\n",
    "print(count_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2629bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b83577ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda(), y\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m mse \u001b[38;5;241m=\u001b[39m loss(out\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y\u001b[38;5;241m.\u001b[39mview(batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     13\u001b[0m mse\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/observer/linear/fno/fourier.py:83\u001b[0m, in \u001b[0;36mFNO1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw0(x)\n\u001b[1;32m     82\u001b[0m x \u001b[38;5;241m=\u001b[39m x1 \u001b[38;5;241m+\u001b[39m x2\n\u001b[0;32m---> 83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mgelu(x)\n\u001b[1;32m     85\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     86\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "train_mseArr = []\n",
    "test_mseArr = []\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    for x, y in trainData:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        mse = loss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "        mse.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    test_mse = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in testData:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            \n",
    "            out = model(x)\n",
    "            test_mse += loss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "            \n",
    "    train_mse /= len(trainData)\n",
    "    test_mse /= len(testData)\n",
    "    \n",
    "    train_mseArr.append(train_mse)\n",
    "    test_mseArr.append(test_mse)\n",
    "    \n",
    "    t2 = default_timer()\n",
    "    if ep%50 == 0:\n",
    "        print(ep, t2-t1, train_mse, test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_mseArr, label=\"Train\")\n",
    "plt.plot(test_mseArr, label=\"Test\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcffa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "with torch.no_grad():\n",
    "    for x, y in testData:\n",
    "        x, y = x.cuda(), y.cuda()   \n",
    "        out = model(x)\n",
    "    for i in range(3):\n",
    "        plt.figure()\n",
    "        plt.plot(out[i].cpu().detach().numpy(), label=\"Guess from GRU\")\n",
    "        plt.plot(y[i].cpu().detach().numpy(), label=\"Correct\")\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f47aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b645c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
